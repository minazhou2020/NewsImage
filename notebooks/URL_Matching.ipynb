{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f75bb4",
   "metadata": {},
   "source": [
    " **This is a sample of how to use URL_Matching class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679fb56",
   "metadata": {},
   "source": [
    "## URL Matching based Method\n",
    "- Feature Extraction: extract article url and image url from provided file\n",
    "- remove manually defined stop words from urls\n",
    "- URL tokenization\n",
    "- URL comparison: a pair of image url and article url is considered to be matched if they contains more than one common tokens. \n",
    "- sort the potential matched image list by the number of same tokens\n",
    "- Evaluate this performance of this method using MR100 on both training dataset and evaluation dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7cbe60",
   "metadata": {},
   "source": [
    "Define stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b291f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['in', 'der', 'die', 'und', 'im', 'auf', 'mit', 'fuer', 'von', 'den', 'an', 'fc', 'das', 'am',\n",
    "                   'vor', 'aus', 'dem', 'anfang', 'sich', 'bei', 'ein', 'des', 'zu', 'sind', 'eine', 'ueber',\n",
    "                   'gegen', 'nach', 'ist', 'zum', 'beim', 'wird', 'nrw', 'nicht', 'als', 'mehr', 'ab', 'zur',\n",
    "                   'werden', 'hat', 's', 'wie', 'einem', 'auch', 'e', 'unter', 'wieder', 'vom', 'so', 'um',\n",
    "                   'noch', 'will', 'afd', 'war', 'strasse']\n",
    "test_img_file = \"MediaEvalNewsImagesBatch04images.tsv\"\n",
    "test_article_file = \"MediaEvalNewsImagesBatch04articles.tsv\"\n",
    "\n",
    "TR_A_ID_IDX = 1\n",
    "TR_I_ID_IDX = 4\n",
    "TR_IMG_URL_IDX = 3\n",
    "TR_TITLE_IDX = 2\n",
    "\n",
    "TEST_A_ID_IDX = 0\n",
    "TEST_I_ID_IDX = 1\n",
    "TEST_IMG_URL_IDX = 0\n",
    "TEST_TITLE_IDX = 2\n",
    "data_folder=r\"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4b8cf",
   "metadata": {},
   "source": [
    "Extract the ground truth: the url paris in the training/evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fdfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gt(gt_file):\n",
    "    ground_truth = {}\n",
    "    with open(gt_file, encoding='utf-8') as file:\n",
    "        next(file)\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            segs = line.split(\"\\t\")\n",
    "            if len(segs) < 3:\n",
    "                break\n",
    "            ar_id = segs[TR_A_ID_IDX]\n",
    "            img_id = segs[TR_I_ID_IDX]\n",
    "            ground_truth[ar_id] = img_id\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372d4fc",
   "metadata": {},
   "source": [
    "Extract image url tokens from give files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b697cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_url_token(img_url_file, id_idx, img_url_idx):\n",
    "    img_id_name_dict = {}\n",
    "    with open(img_url_file, encoding='utf-8') as file:\n",
    "        next(file)\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            segs = line.split(\"\\t\")\n",
    "            if len(segs) < 3:\n",
    "                break\n",
    "            img_id = segs[id_idx]\n",
    "            img_name_full = segs[img_url_idx].split(\"/\")\n",
    "            img_name = img_name_full[len(img_name_full) - 1]\n",
    "            tokens = img_name.split(\".\")[0].split(\"-\")\n",
    "            tokens = [item for item in tokens if item.isalpha() and item != \"null\"]\n",
    "            img_id_name_dict[img_id] = tokens\n",
    "    return img_id_name_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628f103",
   "metadata": {},
   "source": [
    "Extract article url tokens from give files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d6fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_token(article_file, a_id_idx, ar_name_idx):\n",
    "    art_id_name_dict = {}\n",
    "    with open(article_file, encoding=\"utf8\") as file:\n",
    "        next(file)\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            segs = line.split(\"\\t\")\n",
    "            if len(segs) < 3:\n",
    "                break\n",
    "            ar_id = segs[a_id_idx]\n",
    "            ar_name_full = segs[ar_name_idx].split(\"/\")\n",
    "            ar_name = ar_name_full[len(ar_name_full) - 1]\n",
    "            tokens = ar_name.split(\".\")[0].split(\"-\")\n",
    "            tokens = [item for item in tokens if item.isalpha() and item != \"null\"]\n",
    "            art_id_name_dict[ar_id] = tokens\n",
    "        return art_id_name_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd3ec3",
   "metadata": {},
   "source": [
    "Find the matched URL paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c95b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_url(art_id_name_dict, img_id_name_dict):\n",
    "    print(\"matching url\")\n",
    "    candidates = {}\n",
    "    total = 0\n",
    "    result = {}\n",
    "    for art_k, art_v in art_id_name_dict.items():\n",
    "        cnt = 0\n",
    "        flag = False\n",
    "\n",
    "        for img_k, img_v in img_id_name_dict.items():\n",
    "            common_elements = [x for x in art_v if x in img_v and x not in stop_words and len(x) > 1]\n",
    "            if len(common_elements) > 0:\n",
    "                if art_k not in result:\n",
    "                    result[art_k] = []\n",
    "                result[art_k].append((img_k, len(common_elements)))\n",
    "                flag = True\n",
    "                cnt += 1\n",
    "                for ele in common_elements:\n",
    "                    if ele not in candidates:\n",
    "                        candidates[ele] = 0\n",
    "                    candidates[ele] += 1\n",
    "        if art_k in result:\n",
    "            temp_list = result[art_k]\n",
    "            temp_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            result[art_k] = [i[0] for i in temp_list]\n",
    "        if flag:\n",
    "            total += 1\n",
    "    print(total)\n",
    "    print(len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1e569",
   "metadata": {},
   "source": [
    "Write url matching results into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a241c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_url_sim(result_file, result):\n",
    "    with open(result_file, 'a') as the_file:\n",
    "        for art_id, image_list in result.items():\n",
    "            line = art_id\n",
    "            for image in image_list:\n",
    "                line += \"\\t\" + image\n",
    "                the_file.write(line)\n",
    "    the_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a27546",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36d15d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching url\n",
      "1772\n",
      "1772\n"
     ]
    }
   ],
   "source": [
    "test_article_file = \"MediaEvalNewsImagesBatch04articles.tsv\"\n",
    "img_id_name_dict = extract_img_url_token(os.path.join(data_folder, test),\n",
    "                                              TEST_I_ID_IDX,\n",
    "                                              TEST_IMG_URL_IDX)\n",
    "article_id_name_dict = extract_article_token(os.path.join(data_folder, test_article_file),\n",
    "                                                  TEST_A_ID_IDX,\n",
    "                                                  TEST_TITLE_IDX)\n",
    "result = match_url(article_id_name_dict, img_id_name_dict)\n",
    "write_url_sim(\"result/test_url_matching.tsv\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592693d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69140e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result, ground_truth):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for ar_id, img_id in ground_truth.items():\n",
    "        if ar_id in result:\n",
    "            if img_id in result[ar_id][0:100]:\n",
    "                count += 1\n",
    "        total += 1\n",
    "    return count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4cfc2a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2387\n",
      "matching url\n",
      "2246\n",
      "2246\n",
      "MR100 in evaluation dataset is  0.4377880184331797\n"
     ]
    }
   ],
   "source": [
    "evaluation_file='content2019-03-v3.tsv'\n",
    "tr_file=os.path.join(data_folder, evaluation_file)\n",
    "ground_truth = extract_gt(tr_file)\n",
    "img_id_name_dict = extract_img_url_token(tr_file, TR_I_ID_IDX, TR_IMG_URL_IDX)\n",
    "article_id_name_dict = extract_article_token(tr_file, TR_A_ID_IDX, TR_TITLE_IDX)\n",
    "print(len(article_id_name_dict))\n",
    "result = match_url(article_id_name_dict, img_id_name_dict)\n",
    "write_url_sim(\"result/eval_url_matching.tsv\",result)\n",
    "evaluation_result = evaluate(result, ground_truth)\n",
    "print(\"MR100 in evaluation dataset is \", evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7dad25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n",
      "matching url\n",
      "4958\n",
      "4958\n",
      "MR100 in training dataset is  0.40773867392572427\n"
     ]
    }
   ],
   "source": [
    "tr_file=r\"processed_data/data/train.tsv\"\n",
    "ground_truth = extract_gt(tr_file)\n",
    "img_id_name_dict = extract_img_url_token(tr_file, TR_I_ID_IDX, TR_IMG_URL_IDX)\n",
    "article_id_name_dict = extract_article_token(tr_file, TR_A_ID_IDX, TR_TITLE_IDX)\n",
    "print(len(article_id_name_dict))\n",
    "result = match_url(article_id_name_dict, img_id_name_dict)\n",
    "write_url_sim(\"result/tr_url_matching.tsv\",result)\n",
    "tr_result = evaluate(result, ground_truth)\n",
    "print(\"MR100 in training dataset is \", tr_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
